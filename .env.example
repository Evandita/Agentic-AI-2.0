# ==============================================
# GEMINI API CONFIGURATION
# ==============================================
GEMINI_API_KEY=your_gemini_api_key_here
# Get your API key from: https://aistudio.google.com/app/apikey

# ==============================================
# OLLAMA CONFIGURATION
# ==============================================
OLLAMA_BASE_URL=http://localhost:11434
# Default local Ollama server URL
# Change if running Ollama on different host/port

OLLAMA_MODEL=llama3.1
# Default model: llama3.1
# Other options: llama3.2, mistral, codellama, etc.
# Must be pulled locally: ollama pull llama3.1

# ==============================================
# DISPLAY CONFIGURATION (Optional)
# ==============================================
CONSOLE_WIDTH=auto
# auto = dynamic terminal width detection
# or specify fixed width: 80, 100, 120

LOG_LEVEL=INFO
# Options: DEBUG, INFO, WARNING, ERROR

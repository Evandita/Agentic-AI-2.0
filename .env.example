# ==============================================
# GEMINI API CONFIGURATION
# ==============================================
GEMINI_API_KEY=your_gemini_api_key_here
# Get your API key from: https://aistudio.google.com/app/apikey

# ==============================================
# OLLAMA CONFIGURATION
# ==============================================
OLLAMA_BASE_URL=http://localhost:11434
# Default local Ollama server URL
# Change if running Ollama on different host/port

OLLAMA_MODEL=llama3.1
# Default model: llama3.1
# Other options: llama3.2, mistral, codellama, etc.
# Must be pulled locally: ollama pull llama3.1

# ==============================================
# HUGGING FACE API CONFIGURATION
# ==============================================
HUGGINGFACE_API_KEY=your_huggingface_api_key_here
# Get your API key from: https://huggingface.co/settings/tokens

HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.1
# Default conversational model
# Other options: microsoft/DialoGPT-large, facebook/blenderbot-400M-distill
# Full list: https://huggingface.co/models?pipeline_tag=text-generation
CONSOLE_WIDTH=auto
# auto = dynamic terminal width detection
# or specify fixed width: 80, 100, 120

LOG_LEVEL=INFO
# Options: DEBUG, INFO, WARNING, ERROR
